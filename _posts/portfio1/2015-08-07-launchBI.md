---
layout: default
title: CV
category: timeline
tags: portfolio
quote: Week 3, Launch Telecom Business Intelligence Project
---

I worked in telecom industry for three years as IT engineer, project manager and Billing expert. The pains of customers' report requirements and the limitation of our company's telecom business intelligence system inspire me to create a easy to use, easy to maintainance and affortable data analysis system for small and medium telecom companies. The vision is that the system is easy enough which can be installed and maintained part-timely by IT engineer, the configuration of adding new data analysis functions is easy enough that no data analysis experts required, and the system is free for basic data analysis requirements and buy customerized function just as shopping online.

Because I clearly know what current telecom companies expectation and have experience to manage a technic project, I am very confident that the project is valuable enough to attract customers and investors. Meanwhile, Some classmates are interested in this project after talking the project with them. We create a team and begin to start the work.

Considering the situation of telecom industry and data analysis requirements, the structure of the system is divided into three parts: UI, Server and Data analysis Engine.

Data Analysis Engine reads data from database or data file and do data static, data analysis, and data learning. The engine will be written by Scala language, run on Spark Map/Reduce Engine and process data on Hadoop HDFS (processing managed by Hadoop YARN). Data analysis result will be written on MongoDB.

1. Server reads processed data from MongoDB, transforms it to JSON format and finally provides JSON data as RESTful services.
2. UI includes Web, iOS and Android platform. It uses javascript to acquire RESTful services from server and show data and chart on UI.

So good so far. We do researches on all of technologies mentioned above. Danyang Li constructs a proto server to provide RESTful login services. Jun Chen writes a first Spark map/reduce program using Scala. Hongyu Gao and Yiyuan Zhou design a proto UI of web and a logo of project. I setup a distributed Spark running environment on Amazon virtual servers and create auto-deploy shell script to get source code from github, compile and renew service on Amazon virtual servers. In group discussion, we also get a name "Daramid" for the project. The name comes from Data Pyramid which means extract valuable and well organized data from large scale raw data.
